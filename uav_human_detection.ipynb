{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Human Detection in UAV Imagery\n",
    "## HIT-UAV Infrared Thermal Dataset - Baseline vs Augmented Comparison\n",
    "\n",
    "**Experiment Design:**\n",
    "- **Model A**: Trained on clean/normal data only\n",
    "- **Model B**: Trained with SAR augmentations (snow, smoke/fire, thermal artifacts)\n",
    "- **Evaluation**: Compare both on clean and perturbed test sets\n",
    "\n",
    "**Dataset**: HIT-UAV from Kaggle (thermal infrared UAV imagery)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: ENVIRONMENT SETUP\n",
    "# =============================================================================\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Install required packages.\"\"\"\n",
    "    packages = [\n",
    "        'torch', 'torchvision', 'albumentations>=1.3.0', 'pycocotools',\n",
    "        'opencv-python-headless', 'matplotlib', 'numpy', 'Pillow',\n",
    "        'tqdm', 'scipy', 'kaggle'\n",
    "    ]\n",
    "    for pkg in packages:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])\n",
    "    print(\"Packages installed\")\n",
    "\n",
    "install_packages()\n",
    "\n",
    "# No Google Drive mounting; data is stored locally under Config.DATA_ROOT when running in Colab or locally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: IMPORTS AND CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "class Config:\n",
    "    # Paths\n",
    "    IN_COLAB = bool(os.environ.get('COLAB_GPU') or os.environ.get('KAGGLE_KERNEL_RUN_TYPE') or 'google.colab' in str(getattr(__import__('sys'), 'modules', {})))\n",
    "    BASE_DIR = Path('/content') if IN_COLAB else Path('.')\n",
    "    DATA_ROOT = BASE_DIR / 'hit-uav'\n",
    "    CHECKPOINT_DIR = BASE_DIR / 'checkpoints'\n",
    "    OUTPUT_DIR = BASE_DIR / 'outputs'\n",
    "\n",
    "    # Image settings\n",
    "    IMG_SIZE = 512\n",
    "\n",
    "    # Training settings\n",
    "    BATCH_SIZE = 4\n",
    "    NUM_EPOCHS = 6\n",
    "    LR = 0.005\n",
    "    LR_STEP_SIZE = 3\n",
    "    LR_GAMMA = 0.1\n",
    "    WEIGHT_DECAY = 0.0005\n",
    "\n",
    "    # Detection settings\n",
    "    NUM_CLASSES = 6  # background + 5 HIT-UAV classes\n",
    "    IOU_THRESHOLD = 0.5\n",
    "    CONF_THRESHOLD = 0.5\n",
    "\n",
    "    # Flags\n",
    "    USE_YOLO_DIRECT = True  # always use provided YOLO labels\n",
    "    ENABLE_SYNTH_AUG = True  # overlay perturbations on all images when enabled\n",
    "\n",
    "    # Device\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    SEED = 42\n",
    "\n",
    "# Set seeds\n",
    "torch.manual_seed(Config.SEED)\n",
    "np.random.seed(Config.SEED)\n",
    "random.seed(Config.SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(Config.SEED)\n",
    "\n",
    "# Ensure dirs\n",
    "for p in [Config.DATA_ROOT, Config.CHECKPOINT_DIR, Config.OUTPUT_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Device: {Config.DEVICE}\")\n",
    "print(f\"Image size: {Config.IMG_SIZE}, Epochs: {Config.NUM_EPOCHS}, Batch: {Config.BATCH_SIZE}\")\n",
    "print(f\"Data root: {Config.DATA_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Download HIT-UAV Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# CELL 3: DOWNLOAD HIT-UAV DATASET FROM KAGGLE (YOLO FORMAT)\n",
    "# =============================================================================\n",
    "\n",
    "import tarfile\n",
    "\n",
    "def download_hituav_kaggle(data_root: Path) -> bool:\n",
    "    \"\"\"Download and unpack HIT-UAV dataset to the expected YOLO structure.\n",
    "    Resulting layout:\n",
    "    data_root/\n",
    "      dataset.yaml\n",
    "      images/\n",
    "      labels/\n",
    "    \"\"\"\n",
    "    data_root.mkdir(parents=True, exist_ok=True)\n",
    "    images_dir = data_root / \"images\"\n",
    "    labels_dir = data_root / \"labels\"\n",
    "    zip_path = data_root / \"hituav.zip\"\n",
    "\n",
    "    if images_dir.exists() and labels_dir.exists() and list(images_dir.glob('*')):\n",
    "        print(f\"Dataset already prepared at {data_root}\")\n",
    "        return True\n",
    "\n",
    "    print(\"Downloading HIT-UAV dataset from Kaggle via curl...\")\n",
    "    try:\n",
    "        import subprocess\n",
    "        subprocess.run([\n",
    "            'curl', '-L', '-o', str(zip_path),\n",
    "            'https://www.kaggle.com/api/v1/datasets/download/pandrii000/hituav-a-highaltitude-infrared-thermal-dataset'\n",
    "        ], check=True, timeout=600)\n",
    "    except Exception as e:\n",
    "        print(f\"Curl download failed: {e}\")\n",
    "        return False\n",
    "\n",
    "    if not zip_path.exists() or zip_path.stat().st_size < 1_000_000:\n",
    "        print(\"Download seems incomplete; aborting.\")\n",
    "        return False\n",
    "\n",
    "    print(\"Extracting zip...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "        zf.extractall(data_root / 'raw')\n",
    "    zip_path.unlink(missing_ok=True)\n",
    "\n",
    "    # Find directories containing images/labels\n",
    "    raw_root = data_root / 'raw'\n",
    "    candidate = None\n",
    "    for p in raw_root.rglob('images'):\n",
    "        lbl = p.parent / 'labels'\n",
    "        if lbl.exists():\n",
    "            candidate = (p, lbl)\n",
    "            break\n",
    "    if candidate is None:\n",
    "        print(\"Could not locate images/labels after extraction.\")\n",
    "        return False\n",
    "\n",
    "    src_images, src_labels = candidate\n",
    "    images_dir.mkdir(exist_ok=True)\n",
    "    labels_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Move files into flattened structure\n",
    "    for f in src_images.glob('*'):\n",
    "        if f.suffix.lower() in ['.jpg', '.png', '.jpeg']:\n",
    "            shutil.move(str(f), images_dir / f.name)\n",
    "    for f in src_labels.glob('*.txt'):\n",
    "        shutil.move(str(f), labels_dir / f.name)\n",
    "\n",
    "    # Create minimal dataset.yaml for reference (not used by this notebook but helpful for Colab)\n",
    "    yaml_path = data_root / 'dataset.yaml'\n",
    "    if not yaml_path.exists():\n",
    "        class_names = ['person', 'car', 'bicycle', 'othervehicle', 'dontcare']\n",
    "        yaml_content = \"\"\"train: images\n",
    "val: images\n",
    "test: images\n",
    "\n",
    "names:\n",
    "\"\"\" + \"\n",
    "\".join([f\"  {i}: {name}\" for i, name in enumerate(class_names)]) + \"\n",
    "\"\n",
    "        with open(yaml_path, 'w') as f:\n",
    "            f.write(yaml_content)\n",
    "\n",
    "    print(f\"Prepared dataset at {data_root}\")\n",
    "    print(f\" images: {len(list(images_dir.glob('*')))} | labels: {len(list(labels_dir.glob('*.txt')))}\")\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "success = download_hituav_kaggle(Config.DATA_ROOT)\n",
    "if not success:\n",
    "    raise SystemExit(\"Dataset download/prep failed. Please ensure Kaggle API access is available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Convert HIT-UAV to COCO Format (Person Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# CELL 4: DATASET SANITY CHECK (NO CONVERSION)\n",
    "# =============================================================================\n",
    "\n",
    "def show_dataset_overview(data_root: Path):\n",
    "    images_dir = data_root / 'images'\n",
    "    labels_dir = data_root / 'labels'\n",
    "    image_files = sorted(list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png')))\n",
    "    label_files = sorted(list(labels_dir.glob('*.txt')))\n",
    "    print(f\"Images: {len(image_files)}, Labels: {len(label_files)}\")\n",
    "    if image_files:\n",
    "        print(f\"Sample image: {image_files[0].name}\")\n",
    "    if label_files:\n",
    "        print(f\"Sample label: {label_files[0].name}\")\n",
    "        with open(label_files[0], 'r') as f:\n",
    "            for line in f.readlines()[:5]:\n",
    "                print('  ', line.strip())\n",
    "\n",
    "show_dataset_overview(Config.DATA_ROOT)\n",
    "\n",
    "IMAGES_DIR = Config.DATA_ROOT / 'images'\n",
    "LABELS_DIR = Config.DATA_ROOT / 'labels'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: SAR Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: SAR AUGMENTATIONS\n",
    "# Snow, Smoke/Fire, Thermal artifacts for robustness\n",
    "# =============================================================================\n",
    "\n",
    "class SARaugmentations:\n",
    "    \"\"\"Realistic augmentations for SAR drone imagery.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_perlin_noise(shape: Tuple[int, int], scale: float = 100.0) -> np.ndarray:\n",
    "        \"\"\"Generate Perlin-like noise using octaves of Gaussian noise.\"\"\"\n",
    "        h, w = shape\n",
    "        noise = np.zeros((h, w), dtype=np.float32)\n",
    "        \n",
    "        for octave in range(4):\n",
    "            freq = 2 ** octave\n",
    "            amplitude = 1.0 / freq\n",
    "            small_h = max(2, int(h / (scale / freq)))\n",
    "            small_w = max(2, int(w / (scale / freq)))\n",
    "            small_noise = np.random.randn(small_h, small_w).astype(np.float32)\n",
    "            upscaled = cv2.resize(small_noise, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "            noise += amplitude * upscaled\n",
    "        \n",
    "        noise = (noise - noise.min()) / (noise.max() - noise.min() + 1e-8)\n",
    "        return noise\n",
    "    \n",
    "    @staticmethod\n",
    "    def apply_snow(img: np.ndarray, intensity: float = 0.5) -> np.ndarray:\n",
    "        \"\"\"Apply realistic snow effect.\"\"\"\n",
    "        h, w = img.shape[:2]\n",
    "        is_color = len(img.shape) == 3\n",
    "        \n",
    "        snow_noise = SARaugmentations.generate_perlin_noise((h, w), scale=50.0)\n",
    "        fine_noise = np.random.rand(h, w).astype(np.float32)\n",
    "        fine_noise = cv2.GaussianBlur(fine_noise, (5, 5), 0)\n",
    "        \n",
    "        snow_layer = 0.6 * snow_noise + 0.4 * fine_noise\n",
    "        snow_layer = np.clip(snow_layer * intensity * 255, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        if is_color:\n",
    "            snow_layer = cv2.cvtColor(snow_layer, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        img_float = img.astype(np.float32)\n",
    "        mean_val = np.mean(img_float)\n",
    "        contrast_reduction = 0.3\n",
    "        img_reduced = (1 - contrast_reduction) * img_float + contrast_reduction * mean_val\n",
    "        \n",
    "        alpha = intensity * 0.7\n",
    "        result = (1 - alpha) * img_reduced + alpha * snow_layer.astype(np.float32)\n",
    "        return np.clip(result, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    @staticmethod\n",
    "    def apply_smoke_fire(img: np.ndarray, smoke_intensity: float = 0.4, \n",
    "                         fire_intensity: float = 0.3) -> np.ndarray:\n",
    "        \"\"\"Apply smoke and fire effects.\"\"\"\n",
    "        h, w = img.shape[:2]\n",
    "        if len(img.shape) != 3:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        result = img.astype(np.float32)\n",
    "        \n",
    "        # Smoke\n",
    "        smoke_noise = SARaugmentations.generate_perlin_noise((h, w), scale=80.0)\n",
    "        gradient = np.linspace(1.0, 0.3, h).reshape(-1, 1)\n",
    "        gradient = np.tile(gradient, (1, w))\n",
    "        smoke_mask = smoke_noise * gradient\n",
    "        \n",
    "        smoke_color = np.array([180, 180, 180], dtype=np.float32)\n",
    "        smoke_layer = np.ones((h, w, 3), dtype=np.float32) * smoke_color\n",
    "        smoke_layer = cv2.GaussianBlur(smoke_layer, (21, 21), 0)\n",
    "        \n",
    "        smoke_alpha = smoke_mask[..., np.newaxis] * smoke_intensity\n",
    "        result = result * (1 - smoke_alpha) + smoke_layer * smoke_alpha\n",
    "        \n",
    "        # Fire\n",
    "        if fire_intensity > 0:\n",
    "            fx, fy = np.random.randint(w//4, 3*w//4), np.random.randint(h//2, h)\n",
    "            y_coords, x_coords = np.ogrid[:h, :w]\n",
    "            dist = np.sqrt((x_coords - fx)**2 + (y_coords - fy)**2)\n",
    "            fire_radius = min(h, w) // 3\n",
    "            fire_mask = np.clip(1 - dist / fire_radius, 0, 1) ** 2\n",
    "            \n",
    "            fire_color = np.array([30, 100, 255], dtype=np.float32)  # Orange BGR\n",
    "            fire_layer = np.ones((h, w, 3), dtype=np.float32) * fire_color\n",
    "            \n",
    "            fire_alpha = fire_mask[..., np.newaxis] * fire_intensity\n",
    "            result = result * (1 - fire_alpha) + fire_layer * fire_alpha\n",
    "        \n",
    "        return np.clip(result, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    @staticmethod\n",
    "    def apply_thermal_artifacts(img: np.ndarray, intensity_scale: float = 1.0,\n",
    "                                sensor_noise: float = 0.05) -> np.ndarray:\n",
    "        \"\"\"Apply thermal camera artifacts.\"\"\"\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        if len(img.shape) == 3:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = img.copy()\n",
    "        \n",
    "        result = gray.astype(np.float32) * intensity_scale\n",
    "        \n",
    "        # Sensor noise\n",
    "        noise = np.random.normal(0, sensor_noise * 255, (h, w)).astype(np.float32)\n",
    "        if np.random.rand() < 0.3:\n",
    "            line_noise = np.random.normal(0, sensor_noise * 50, (h, 1))\n",
    "            noise += np.tile(line_noise, (1, w))\n",
    "        \n",
    "        result += noise\n",
    "        result = np.clip(result, 0, 255).astype(np.uint8)\n",
    "        return cv2.cvtColor(result, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    @staticmethod\n",
    "    def apply_random(img: np.ndarray) -> Tuple[np.ndarray, str]:\n",
    "        \"\"\"Apply random SAR augmentation.\"\"\"\n",
    "        aug_type = np.random.choice(['snow', 'fire', 'thermal', 'none'])\n",
    "        \n",
    "        if aug_type == 'snow':\n",
    "            return SARaugmentations.apply_snow(img, np.random.uniform(0.3, 0.6)), 'snow'\n",
    "        elif aug_type == 'fire':\n",
    "            return SARaugmentations.apply_smoke_fire(img, np.random.uniform(0.2, 0.4),\n",
    "                                                     np.random.uniform(0.2, 0.4)), 'fire'\n",
    "        elif aug_type == 'thermal':\n",
    "            return SARaugmentations.apply_thermal_artifacts(img, np.random.uniform(0.8, 1.2),\n",
    "                                                            np.random.uniform(0.03, 0.08)), 'thermal'\n",
    "        return img, 'none'\n",
    "\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"Visualizing SAR augmentations on actual dataset images\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Use actual dataset images for visualization\n",
    "sample_imgs = list(IMAGES_DIR.glob(\"*.jpg\"))\n",
    "\n",
    "if len(sample_imgs) > 0:\n",
    "    # Get 4 random samples from the dataset\n",
    "    samples_to_show = random.sample(sample_imgs, min(4, len(sample_imgs)))\n",
    "    \n",
    "    print(f\"\\nShowing {len(samples_to_show)} random images from the dataset:\")\n",
    "    for img_path in samples_to_show:\n",
    "        print(f\"  - {img_path.name}\")\n",
    "    \n",
    "    fig, axes = plt.subplots(len(samples_to_show), 4, figsize=(16, 4 * len(samples_to_show)))\n",
    "    if len(samples_to_show) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for row_idx, img_path in enumerate(samples_to_show):\n",
    "        sample = cv2.imread(str(img_path))\n",
    "        if sample is None:\n",
    "            continue\n",
    "        \n",
    "        # Original\n",
    "        axes[row_idx, 0].imshow(cv2.cvtColor(sample, cv2.COLOR_BGR2RGB))\n",
    "        axes[row_idx, 0].set_title(f'Original\\n{img_path.name}')\n",
    "        axes[row_idx, 0].axis('off')\n",
    "        \n",
    "        # Snow\n",
    "        snow_aug = SARaugmentations.apply_snow(sample, 0.5)\n",
    "        axes[row_idx, 1].imshow(cv2.cvtColor(snow_aug, cv2.COLOR_BGR2RGB))\n",
    "        axes[row_idx, 1].set_title('Snow')\n",
    "        axes[row_idx, 1].axis('off')\n",
    "        \n",
    "        # Smoke/Fire\n",
    "        fire_aug = SARaugmentations.apply_smoke_fire(sample, 0.4, 0.4)\n",
    "        axes[row_idx, 2].imshow(cv2.cvtColor(fire_aug, cv2.COLOR_BGR2RGB))\n",
    "        axes[row_idx, 2].set_title('Smoke/Fire')\n",
    "        axes[row_idx, 2].axis('off')\n",
    "        \n",
    "        # Thermal Artifacts\n",
    "        thermal_aug = SARaugmentations.apply_thermal_artifacts(sample, 1.1, 0.06)\n",
    "        axes[row_idx, 3].imshow(cv2.cvtColor(thermal_aug, cv2.COLOR_BGR2RGB))\n",
    "        axes[row_idx, 3].set_title('Thermal Artifacts')\n",
    "        axes[row_idx, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{Config.OUTPUT_DIR}/augmentations_dataset_samples.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"\\nAugmentations saved to: {Config.OUTPUT_DIR}/augmentations_dataset_samples.png\")\n",
    "    \n",
    "    # Test random augmentation\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"Testing apply_random() on dataset images:\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx in range(6):\n",
    "        sample_img = cv2.imread(str(random.choice(sample_imgs)))\n",
    "        if sample_img is not None:\n",
    "            aug_img, aug_type = SARaugmentations.apply_random(sample_img)\n",
    "            axes[idx].imshow(cv2.cvtColor(aug_img, cv2.COLOR_BGR2RGB))\n",
    "            axes[idx].set_title(f'Random Aug: {aug_type}')\n",
    "            axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{Config.OUTPUT_DIR}/augmentations_random_samples.png\", dpi=150)\n",
    "    plt.show()\n",
    "    print(f\"Random augmentations saved to: {Config.OUTPUT_DIR}/augmentations_random_samples.png\")\n",
    "    \n",
    "else:\n",
    "    print(\"WARNING: No images found in IMAGES_DIR. Cannot visualize augmentations.\")\n",
    "    print(f\"IMAGES_DIR: {IMAGES_DIR}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SAR augmentations defined and tested successfully!\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Dataset Class with Proper Box Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# CELL 6: DATASET CLASS\n",
    "# Proper handling of box formats; uses native YOLO labels directly (no COCO conversion)\n",
    "# =============================================================================\n",
    "\n",
    "CLASS_NAMES = ['person', 'car', 'bicycle', 'othervehicle', 'dontcare']\n",
    "\n",
    "class UAVDetectionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for UAV detection using YOLO .txt labels directly.\n",
    "    All classes are retained; labels are shifted by +1 to reserve 0 for background.\n",
    "    \"\"\"\n",
    "    def __init__(self, images_dir, labels_dir, transforms=None,\n",
    "                 apply_sar_aug=False, sar_aug_prob=1.0, selected_files=None):\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.labels_dir = Path(labels_dir)\n",
    "        self.transforms = transforms\n",
    "        self.apply_sar_aug = apply_sar_aug\n",
    "        self.sar_aug_prob = sar_aug_prob\n",
    "        candidate_files = selected_files if selected_files is not None else (\n",
    "            list(self.images_dir.glob('*.jpg')) + list(self.images_dir.glob('*.png'))\n",
    "        )\n",
    "        self.image_files = [Path(p) for p in candidate_files\n",
    "                            if (self.labels_dir / f\"{Path(p).stem}.txt\").exists()]\n",
    "        self.img_ids = list(range(len(self.image_files)))\n",
    "        print(f\"Dataset initialized (YOLO): {len(self.img_ids)} images with labels\")\n",
    "        print(f\"  - Images dir: {self.images_dir}\")\n",
    "        print(f\"  - Labels dir:  {self.labels_dir}\")\n",
    "        print(f\"  - SAR augmentation: {'Enabled' if self.apply_sar_aug else 'Disabled'} (p={self.sar_aug_prob})\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        # Read YOLO labels\n",
    "        label_path = self.labels_dir / f\"{img_path.stem}.txt\"\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        areas = []\n",
    "        if label_path.exists():\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:\n",
    "                        cls_id = int(parts[0])\n",
    "                        cx, cy, bw, bh = map(float, parts[1:5])\n",
    "                        x = (cx - bw / 2) * w\n",
    "                        y = (cy - bh / 2) * h\n",
    "                        bw_pix = bw * w\n",
    "                        bh_pix = bh * h\n",
    "                        x1, y1, x2, y2 = x, y, x + bw_pix, y + bh_pix\n",
    "                        if x2 > x1 and y2 > y1:\n",
    "                            boxes.append([x1, y1, x2, y2])\n",
    "                            labels.append(cls_id + 1)  # shift for background index 0\n",
    "                            areas.append(bw_pix * bh_pix)\n",
    "\n",
    "        # Apply perturbations to every image if enabled\n",
    "        if self.apply_sar_aug and random.random() < self.sar_aug_prob:\n",
    "            img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            img_aug, _ = SARaugmentations.apply_random(img_bgr)\n",
    "            img = cv2.cvtColor(img_aug, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        img_tensor = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0\n",
    "        if self.transforms:\n",
    "            img_tensor = self.transforms(img_tensor)\n",
    "\n",
    "        if len(boxes) > 0:\n",
    "            boxes_tensor = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            labels_tensor = torch.as_tensor(labels, dtype=torch.int64)\n",
    "            areas_tensor = torch.as_tensor(areas, dtype=torch.float32)\n",
    "        else:\n",
    "            boxes_tensor = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels_tensor = torch.zeros((0,), dtype=torch.int64)\n",
    "            areas_tensor = torch.zeros((0,), dtype=torch.float32)\n",
    "\n",
    "        target = {\n",
    "            'boxes': boxes_tensor,\n",
    "            'labels': labels_tensor,\n",
    "            'image_id': torch.tensor([idx]),\n",
    "            'area': areas_tensor,\n",
    "            'iscrowd': torch.zeros(len(boxes), dtype=torch.int64)\n",
    "        }\n",
    "\n",
    "        return img_tensor, target\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate for detection.\"\"\"\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# Create train/val/test split (70/15/15)\n",
    "\n",
    "# Create train/val/test split (70/15/15)\n",
    "print(f\"\n",
    "{'='*70}\")\n",
    "print(\"Creating train/val/test splits\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "split_roots = {name: Config.DATA_ROOT / name for name in ['train','val','test']}\n",
    "predefined = all((split_roots[name] / 'images').exists() and (split_roots[name] / 'labels').exists() for name in split_roots)\n",
    "\n",
    "if predefined:\n",
    "    print(\"Found predefined splits on disk; using them without reshuffling.\")\n",
    "    TRAIN_FILES = sorted(list((split_roots['train']/ 'images').glob('*.jpg')) + list((split_roots['train']/ 'images').glob('*.png')))\n",
    "    VAL_FILES   = sorted(list((split_roots['val']  / 'images').glob('*.jpg')) + list((split_roots['val']  / 'images').glob('*.png')))\n",
    "    TEST_FILES  = sorted(list((split_roots['test'] / 'images').glob('*.jpg')) + list((split_roots['test'] / 'images').glob('*.png')))\n",
    "else:\n",
    "    print(\"No predefined splits found; creating random 70/15/15 split from images/labels.\")\n",
    "    all_images = sorted(list((Config.DATA_ROOT / 'images').glob('*.jpg')) + list((Config.DATA_ROOT / 'images').glob('*.png')))\n",
    "    all_images = [p for p in all_images if (Config.DATA_ROOT / 'labels' / f\"{p.stem}.txt\").exists()]\n",
    "    random.shuffle(all_images)\n",
    "    n = len(all_images)\n",
    "    train_end = int(0.7 * n)\n",
    "    val_end = int(0.85 * n)\n",
    "    TRAIN_FILES = all_images[:train_end]\n",
    "    VAL_FILES = all_images[train_end:val_end]\n",
    "    TEST_FILES = all_images[val_end:]\n",
    "\n",
    "print(f\"train: {len(TRAIN_FILES)} images\")\n",
    "print(f\"val:   {len(VAL_FILES)} images\")\n",
    "print(f\"test:  {len(TEST_FILES)} images\")\n",
    "\n",
    "test_dataset_no_aug = UAVDetectionDataset(Config.DATA_ROOT / 'images', Config.DATA_ROOT / 'labels',\n",
    "    apply_sar_aug=False, selected_files=TRAIN_FILES)\n",
    "test_dataset_with_aug = UAVDetectionDataset(Config.DATA_ROOT / 'images', Config.DATA_ROOT / 'labels',\n",
    "    apply_sar_aug=True, sar_aug_prob=1.0, selected_files=TRAIN_FILES)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "print(\"\n",
    "Loading and visualizing samples...\")\n",
    "\n",
    "for col in range(4):\n",
    "    idx = random.randint(0, len(test_dataset_no_aug) - 1)\n",
    "    img_tensor, target = test_dataset_no_aug[idx]\n",
    "    img_np = img_tensor.permute(1, 2, 0).numpy()\n",
    "    img_np = (img_np * 255).astype(np.uint8)\n",
    "    boxes = target['boxes'].numpy()\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        cv2.rectangle(img_np, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    axes[0, col].imshow(img_np)\n",
    "    axes[0, col].set_title(f'Original\\n{len(boxes)} box(es)')\n",
    "    axes[0, col].axis('off')\n",
    "\n",
    "for col in range(4):\n",
    "    idx = random.randint(0, len(test_dataset_with_aug) - 1)\n",
    "    img_tensor, target = test_dataset_with_aug[idx]\n",
    "    img_np = img_tensor.permute(1, 2, 0).numpy()\n",
    "    img_np = (img_np * 255).astype(np.uint8)\n",
    "    boxes = target['boxes'].numpy()\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        cv2.rectangle(img_np, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    axes[1, col].imshow(img_np)\n",
    "    axes[1, col].set_title(f'Perturbed\\n{len(boxes)} box(es)')\n",
    "    axes[1, col].axis('off')\n",
    "\n",
    "plt.suptitle('Dataset Loading Test: Original (top) vs Perturbed (bottom)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{Config.OUTPUT_DIR}/dataset_loading_test.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\n",
    "Dataset loading test saved to: {Config.OUTPUT_DIR}/dataset_loading_test.png\")\n",
    "print(f\"{'='*70}\")\n",
    "print(\"Dataset class and splits created successfully!\")\n",
    "print(f\"{'='*70}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Corrected Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: CORRECTED EVALUATION FUNCTION\n",
    "# Properly computes precision, recall, F1 with detailed debugging\n",
    "# =============================================================================\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Compute IoU between two boxes in [x1, y1, x2, y2] format.\n",
    "    \"\"\"\n",
    "    # Intersection\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    \n",
    "    inter_w = max(0, x2 - x1)\n",
    "    inter_h = max(0, y2 - y1)\n",
    "    inter_area = inter_w * inter_h\n",
    "    \n",
    "    # Union\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union_area = area1 + area2 - inter_area\n",
    "    \n",
    "    if union_area <= 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return inter_area / union_area\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, data_loader, device, iou_thresh=0.5, conf_thresh=0.5, verbose=False):\n",
    "    \"\"\"\n",
    "    Evaluate detection model with proper metric computation.\n",
    "    \n",
    "    Returns precision, recall, F1 at given IoU and confidence thresholds.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    total_tp = 0\n",
    "    total_fp = 0\n",
    "    total_fn = 0\n",
    "    total_gt = 0\n",
    "    total_pred = 0\n",
    "    \n",
    "    for batch_idx, (images, targets) in enumerate(tqdm(data_loader, desc=\"Evaluating\", disable=not verbose)):\n",
    "        images = [img.to(device) for img in images]\n",
    "        \n",
    "        # Get predictions\n",
    "        outputs = model(images)\n",
    "        \n",
    "        for output, target in zip(outputs, targets):\n",
    "            # Get ground truth boxes (already in [x1, y1, x2, y2] format from dataset)\n",
    "            gt_boxes = target['boxes'].cpu().numpy()\n",
    "            total_gt += len(gt_boxes)\n",
    "            \n",
    "            # Filter predictions by confidence AND class (person = 1)\n",
    "            scores = output['scores'].cpu().numpy()\n",
    "            pred_boxes = output['boxes'].cpu().numpy()\n",
    "            pred_labels = output['labels'].cpu().numpy()\n",
    "            \n",
    "            # Keep all classes; filter only by confidence\n",
    "            mask = (scores >= conf_thresh)\n",
    "            pred_boxes = pred_boxes[mask]\n",
    "            pred_scores = scores[mask]\n",
    "            total_pred += len(pred_boxes)\n",
    "            \n",
    "            if len(gt_boxes) == 0:\n",
    "                # All predictions are false positives\n",
    "                total_fp += len(pred_boxes)\n",
    "                continue\n",
    "            \n",
    "            if len(pred_boxes) == 0:\n",
    "                # All ground truths are missed\n",
    "                total_fn += len(gt_boxes)\n",
    "                continue\n",
    "            \n",
    "            # Match predictions to ground truth (greedy matching by score)\n",
    "            # Sort predictions by score (descending)\n",
    "            sorted_indices = np.argsort(-pred_scores)\n",
    "            matched_gt = set()\n",
    "            \n",
    "            for pred_idx in sorted_indices:\n",
    "                pred_box = pred_boxes[pred_idx]\n",
    "                \n",
    "                best_iou = 0\n",
    "                best_gt_idx = -1\n",
    "                \n",
    "                for gt_idx, gt_box in enumerate(gt_boxes):\n",
    "                    if gt_idx in matched_gt:\n",
    "                        continue\n",
    "                    \n",
    "                    iou = compute_iou(pred_box, gt_box)\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_gt_idx = gt_idx\n",
    "                \n",
    "                if best_iou >= iou_thresh and best_gt_idx >= 0:\n",
    "                    total_tp += 1\n",
    "                    matched_gt.add(best_gt_idx)\n",
    "                else:\n",
    "                    total_fp += 1\n",
    "            \n",
    "            # Unmatched ground truths are false negatives\n",
    "            total_fn += len(gt_boxes) - len(matched_gt)\n",
    "    \n",
    "    # Compute metrics\n",
    "    precision = total_tp / max(total_tp + total_fp, 1)\n",
    "    recall = total_tp / max(total_tp + total_fn, 1)\n",
    "    f1 = 2 * precision * recall / max(precision + recall, 1e-8)\n",
    "    \n",
    "    metrics = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'tp': total_tp,\n",
    "        'fp': total_fp,\n",
    "        'fn': total_fn,\n",
    "        'total_gt': total_gt,\n",
    "        'total_pred': total_pred\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nEvaluation Results (IoU={iou_thresh}, Conf={conf_thresh}):\")\n",
    "        print(f\"  GT boxes: {total_gt}, Predictions: {total_pred}\")\n",
    "        print(f\"  TP: {total_tp}, FP: {total_fp}, FN: {total_fn}\")\n",
    "        print(f\"  Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "print(\"Evaluation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Model Creation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: MODEL CREATION\n",
    "# =============================================================================\n",
    "\n",
    "def create_detection_model(num_classes=2, pretrained=True, freeze_backbone=True):\n",
    "    \"\"\"\n",
    "    Create Faster R-CNN model for person detection.\n",
    "    \n",
    "    Args:\n",
    "        num_classes: 2 (background + person)\n",
    "        pretrained: Use COCO pretrained weights\n",
    "        freeze_backbone: Freeze early layers to prevent overfitting\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT\n",
    "        model = fasterrcnn_resnet50_fpn(weights=weights)\n",
    "    else:\n",
    "        model = fasterrcnn_resnet50_fpn(weights=None)\n",
    "    \n",
    "    # Replace the classifier head\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    if freeze_backbone:\n",
    "        # Freeze backbone except layer4 and FPN\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'backbone' in name:\n",
    "                if 'layer4' not in name and 'fpn' not in name:\n",
    "                    param.requires_grad = False\n",
    "    \n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Model: {trainable:,} / {total:,} trainable params ({100*trainable/total:.1f}%)\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# YOLOV8 ALTERNATIVE:\n",
    "# from ultralytics import YOLO\n",
    "# model = YOLO('yolov8n.pt')\n",
    "# model.train(data='data.yaml', epochs=6, imgsz=512)\n",
    "# ============================================\n",
    "\n",
    "print(\"Model creation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: TRAINING FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, num_epochs, lr,\n",
    "                checkpoint_prefix=\"model\", lr_step=3, lr_gamma=0.1):\n",
    "    \"\"\"\n",
    "    Train the detection model and track metrics.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    # Optimizer - only train unfrozen params\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=lr, momentum=0.9, weight_decay=Config.WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_step, gamma=lr_gamma)\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_precision': [],\n",
    "        'val_recall': [],\n",
    "        'val_f1': []\n",
    "    }\n",
    "    \n",
    "    best_f1 = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for images, targets in pbar:\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            # Skip batches with no valid targets\n",
    "            valid_targets = [t for t in targets if len(t['boxes']) > 0]\n",
    "            if len(valid_targets) == 0:\n",
    "                continue\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            losses.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(params, max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += losses.item()\n",
    "            num_batches += 1\n",
    "            pbar.set_postfix({'loss': f\"{losses.item():.4f}\"})\n",
    "        \n",
    "        avg_loss = epoch_loss / max(num_batches, 1)\n",
    "        history['train_loss'].append(avg_loss)\n",
    "        \n",
    "        # Validation\n",
    "        metrics = evaluate_model(model, val_loader, device,\n",
    "                                 iou_thresh=Config.IOU_THRESHOLD,\n",
    "                                 conf_thresh=Config.CONF_THRESHOLD)\n",
    "        \n",
    "        history['val_precision'].append(metrics['precision'])\n",
    "        history['val_recall'].append(metrics['recall'])\n",
    "        history['val_f1'].append(metrics['f1'])\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, \"\n",
    "              f\"P={metrics['precision']:.4f}, R={metrics['recall']:.4f}, F1={metrics['f1']:.4f} \"\n",
    "              f\"(TP={metrics['tp']}, FP={metrics['fp']}, FN={metrics['fn']})\")\n",
    "        \n",
    "        # Save best model\n",
    "        if metrics['f1'] > best_f1:\n",
    "            best_f1 = metrics['f1']\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'metrics': metrics,\n",
    "                'history': history\n",
    "            }, f\"{Config.CHECKPOINT_DIR}/{checkpoint_prefix}_best.pth\")\n",
    "            print(f\"  -> Saved best model (F1={best_f1:.4f})\")\n",
    "    \n",
    "    return model, history, best_f1\n",
    "\n",
    "\n",
    "print(\"Training function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Train Model A (Baseline - No SAR Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 10: TRAIN MODEL A - BASELINE (NO AUGMENTATION)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING MODEL A: BASELINE (All images perturbed)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create datasets WITH perturbation applied to every image\n",
    "train_dataset_baseline = UAVDetectionDataset(\n",
    "    IMAGES_DIR, LABELS_DIR,\n",
    "    selected_files=TRAIN_FILES,\n",
    "    apply_sar_aug=True,\n",
    "    sar_aug_prob=1.0\n",
    ")\n",
    "\n",
    "val_dataset = UAVDetectionDataset(\n",
    "    IMAGES_DIR, LABELS_DIR,\n",
    "    selected_files=VAL_FILES,\n",
    "    apply_sar_aug=True,\n",
    "    sar_aug_prob=1.0\n",
    ")\n",
    "\n",
    "train_loader_baseline = DataLoader(\n",
    "    train_dataset_baseline,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# Create and train model A\n",
    "model_A = create_detection_model(\n",
    "    num_classes=Config.NUM_CLASSES,\n",
    "    pretrained=True,\n",
    "    freeze_backbone=True\n",
    ")\n",
    "\n",
    "model_A, history_A, best_f1_A = train_model(\n",
    "    model_A, train_loader_baseline, val_loader, Config.DEVICE,\n",
    "    num_epochs=Config.NUM_EPOCHS,\n",
    "    lr=Config.LR,\n",
    "    checkpoint_prefix=\"model_A_baseline\",\n",
    "    lr_step=Config.LR_STEP_SIZE,\n",
    "    lr_gamma=Config.LR_GAMMA\n",
    ")\n",
    "\n",
    "print(f\"\\nModel A Best F1: {best_f1_A:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Train Model B (With SAR Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# CELL 11: TRAIN MODEL B - WITH SAR AUGMENTATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING MODEL B: WITH SAR AUGMENTATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if Config.ENABLE_SYNTH_AUG:\n",
    "    train_dataset_augmented = UAVDetectionDataset(\n",
    "        IMAGES_DIR, LABELS_DIR,\n",
    "        selected_files=TRAIN_FILES,\n",
    "        apply_sar_aug=True,\n",
    "        sar_aug_prob=0.5\n",
    "    )\n",
    "\n",
    "    train_loader_augmented = DataLoader(\n",
    "        train_dataset_augmented,\n",
    "        batch_size=Config.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    # Create and train model B (fresh model)\n",
    "    model_B = create_detection_model(\n",
    "        num_classes=Config.NUM_CLASSES,\n",
    "        pretrained=True,\n",
    "        freeze_backbone=True\n",
    "    )\n",
    "\n",
    "    model_B, history_B, best_f1_B = train_model(\n",
    "        model_B, train_loader_augmented, val_loader, Config.DEVICE,\n",
    "        num_epochs=Config.NUM_EPOCHS,\n",
    "        lr=Config.LR,\n",
    "        checkpoint_prefix=\"model_B_augmented\",\n",
    "        lr_step=Config.LR_STEP_SIZE,\n",
    "        lr_gamma=Config.LR_GAMMA\n",
    "    )\n",
    "\n",
    "    print(f\"\n",
    "Model B Best F1: {best_f1_B:.4f}\")\n",
    "else:\n",
    "    print(\"Config.ENABLE_SYNTH_AUG=False -> skipping Model B training to avoid synthetic images.\")\n",
    "    model_B = None\n",
    "    history_B = None\n",
    "    best_f1_B = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Create Perturbed Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# CELL 12: CREATE PERTURBED TEST SET\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Creating perturbed test set...\")\n",
    "\n",
    "if Config.ENABLE_SYNTH_AUG:\n",
    "    perturbed_dir = Path(Config.DATA_ROOT) / \"perturbed_test\"\n",
    "    perturbed_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    all_test_files = TEST_FILES\n",
    "    for img_path in tqdm(all_test_files, desc=\"Perturbing test images\"):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        # Apply random perturbation (snow or fire) to every image\n",
    "        aug_type = random.choice(['snow', 'fire'])\n",
    "        if aug_type == 'snow':\n",
    "            perturbed = SARaugmentations.apply_snow(img, random.uniform(0.4, 0.6))\n",
    "        else:\n",
    "            perturbed = SARaugmentations.apply_smoke_fire(img, random.uniform(0.3, 0.5),\n",
    "                                                           random.uniform(0.3, 0.5))\n",
    "        cv2.imwrite(str(perturbed_dir / img_path.name), perturbed)\n",
    "\n",
    "    # Minimal annotations placeholder\n",
    "    PERTURBED_TEST_ANN = perturbed_dir / \"annotations.json\"\n",
    "    with open(PERTURBED_TEST_ANN, 'w') as f:\n",
    "        json.dump({'images':[{'id':i,'file_name':p.name} for i,p in enumerate(all_test_files)],\n",
    "                   'annotations':[], 'categories':[]}, f)\n",
    "\n",
    "    print(f\"Perturbed test set saved to {perturbed_dir}\")\n",
    "else:\n",
    "    print(\"Synthetic perturbations disabled; skipping perturbed test set creation.\")\n",
    "    PERTURBED_TEST_ANN = None\n",
    "    perturbed_dir = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 13: Final Comparison - Both Models on Clean & Perturbed Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# CELL 13: FINAL COMPARISON\n",
    "# Evaluate models on clean (and optionally perturbed) test sets\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"Creating test dataset (clean)...\")\n",
    "test_dataset_clean = UAVDetectionDataset(IMAGES_DIR, LABELS_DIR,\n",
    "                                         selected_files=TEST_FILES,\n",
    "                                         apply_sar_aug=False)\n",
    "\n",
    "test_loader_clean = DataLoader(test_dataset_clean, batch_size=Config.BATCH_SIZE,\n",
    "                               shuffle=False, num_workers=2, collate_fn=collate_fn)\n",
    "\n",
    "metrics_A_clean = evaluate_model(model_A, test_loader_clean, Config.DEVICE,\n",
    "                                 iou_thresh=Config.IOU_THRESHOLD,\n",
    "                                 conf_thresh=Config.CONF_THRESHOLD, verbose=True)\n",
    "\n",
    "print(f\"\n",
    "Model A (Baseline) on CLEAN test set -> P={metrics_A_clean['precision']:.4f}, R={metrics_A_clean['recall']:.4f}, F1={metrics_A_clean['f1']:.4f}\")\n",
    "\n",
    "# Optional: evaluate augmented model and perturbed set when enabled\n",
    "if Config.ENABLE_SYNTH_AUG and model_B is not None and PERTURBED_TEST_ANN is not None and perturbed_dir is not None:\n",
    "    print(\"\n",
    "Creating perturbed test dataset...\")\n",
    "    test_dataset_perturbed = UAVDetectionDataset(perturbed_dir, LABELS_DIR,\n",
    "                                                 selected_files=TEST_FILES,\n",
    "                                                 apply_sar_aug=False)\n",
    "    test_loader_perturbed = DataLoader(test_dataset_perturbed, batch_size=Config.BATCH_SIZE,\n",
    "                                       shuffle=False, num_workers=2, collate_fn=collate_fn)\n",
    "\n",
    "    metrics_A_perturbed = evaluate_model(model_A, test_loader_perturbed, Config.DEVICE,\n",
    "                                         iou_thresh=Config.IOU_THRESHOLD,\n",
    "                                         conf_thresh=Config.CONF_THRESHOLD, verbose=True)\n",
    "\n",
    "    print(\"\n",
    "--- Model B (Augmented) ---\")\n",
    "    print(\"On CLEAN test set:\")\n",
    "    metrics_B_clean = evaluate_model(model_B, test_loader_clean, Config.DEVICE,\n",
    "                                      iou_thresh=Config.IOU_THRESHOLD,\n",
    "                                      conf_thresh=Config.CONF_THRESHOLD, verbose=True)\n",
    "\n",
    "    print(\"\n",
    "On PERTURBED test set:\")\n",
    "    metrics_B_perturbed = evaluate_model(model_B, test_loader_perturbed, Config.DEVICE,\n",
    "                                          iou_thresh=Config.IOU_THRESHOLD,\n",
    "                                          conf_thresh=Config.CONF_THRESHOLD, verbose=True)\n",
    "\n",
    "    # Summary Table\n",
    "    print(\"\n",
    "\" + \"=\"*70)\n",
    "    print(\"SUMMARY TABLE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Model':<20} {'Test Set':<15} {'Precision':<12} {'Recall':<12} {'F1':<12}\")\n",
    "    print(\"-\"*70)\n",
    "    print(f\"{'A (Baseline)':<20} {'Clean':<15} {metrics_A_clean['precision']:.4f}       {metrics_A_clean['recall']:.4f}       {metrics_A_clean['f1']:.4f}\")\n",
    "    print(f\"{'A (Baseline)':<20} {'Perturbed':<15} {metrics_A_perturbed['precision']:.4f}       {metrics_A_perturbed['recall']:.4f}       {metrics_A_perturbed['f1']:.4f}\")\n",
    "    print(f\"{'B (Augmented)':<20} {'Clean':<15} {metrics_B_clean['precision']:.4f}       {metrics_B_clean['recall']:.4f}       {metrics_B_clean['f1']:.4f}\")\n",
    "    print(f\"{'B (Augmented)':<20} {'Perturbed':<15} {metrics_B_perturbed['precision']:.4f}       {metrics_B_perturbed['recall']:.4f}       {metrics_B_perturbed['f1']:.4f}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    drop_A = (metrics_A_clean['f1'] - metrics_A_perturbed['f1']) / max(metrics_A_clean['f1'], 1e-8) * 100\n",
    "    drop_B = (metrics_B_clean['f1'] - metrics_B_perturbed['f1']) / max(metrics_B_clean['f1'], 1e-8) * 100\n",
    "    print(f\"\n",
    "Robustness Analysis:\")\n",
    "    print(f\"  Model A F1 drop on perturbed: {drop_A:.1f}%\")\n",
    "    print(f\"  Model B F1 drop on perturbed: {drop_B:.1f}%\")\n",
    "    print(f\"  Robustness improvement: {drop_A - drop_B:.1f}%\")\n",
    "    if drop_B < drop_A:\n",
    "        print(\"\n",
    "-> Model B (with SAR augmentation) is MORE ROBUST to adverse conditions!\")\n",
    "    else:\n",
    "        print(\"\n",
    "-> Augmentation did not improve robustness (may need tuning)\")\n",
    "else:\n",
    "    print(\"Synthetic augmentation disabled or perturbed set not built; only Model A evaluated on clean test set.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 14: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# CELL 14: VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "if Config.ENABLE_SYNTH_AUG and history_B is not None:\n",
    "    # Training curves comparison (baseline vs augmented)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes[0, 0].plot(history_A['train_loss'], 'b-o', label='Model A (Baseline)')\n",
    "    axes[0, 0].plot(history_B['train_loss'], 'r-s', label='Model B (Augmented)')\n",
    "    axes[0, 0].set_xlabel('Epoch'); axes[0, 0].set_ylabel('Loss'); axes[0, 0].set_title('Training Loss'); axes[0, 0].legend(); axes[0, 0].grid(True)\n",
    "    axes[0, 1].plot(history_A['val_f1'], 'b-o', label='Model A (Baseline)')\n",
    "    axes[0, 1].plot(history_B['val_f1'], 'r-s', label='Model B (Augmented)')\n",
    "    axes[0, 1].set_xlabel('Epoch'); axes[0, 1].set_ylabel('F1 Score'); axes[0, 1].set_title('Validation F1'); axes[0, 1].legend(); axes[0, 1].grid(True)\n",
    "    axes[1, 0].plot(history_A['val_precision'], 'b-o', label='Model A (Baseline)')\n",
    "    axes[1, 0].plot(history_B['val_precision'], 'r-s', label='Model B (Augmented)')\n",
    "    axes[1, 0].set_xlabel('Epoch'); axes[1, 0].set_ylabel('Precision'); axes[1, 0].set_title('Validation Precision'); axes[1, 0].legend(); axes[1, 0].grid(True)\n",
    "    axes[1, 1].plot(history_A['val_recall'], 'b-o', label='Model A (Baseline)')\n",
    "    axes[1, 1].plot(history_B['val_recall'], 'r-s', label='Model B (Augmented)')\n",
    "    axes[1, 1].set_xlabel('Epoch'); axes[1, 1].set_ylabel('Recall'); axes[1, 1].set_title('Validation Recall'); axes[1, 1].legend(); axes[1, 1].grid(True)\n",
    "    plt.tight_layout(); plt.savefig(f\"{Config.OUTPUT_DIR}/training_comparison.png\", dpi=150); plt.show()\n",
    "    # Final metrics bar chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    x = np.arange(3); width = 0.2\n",
    "    metrics_labels = ['Precision', 'Recall', 'F1']\n",
    "    bars1 = ax.bar(x - 1.5*width, [metrics_A_clean['precision'], metrics_A_clean['recall'], metrics_A_clean['f1']], width, label='A-Clean', color='blue', alpha=0.8)\n",
    "    bars3 = ax.bar(x + 0.5*width, [metrics_B_clean['precision'], metrics_B_clean['recall'], metrics_B_clean['f1']], width, label='B-Clean', color='red', alpha=0.8)\n",
    "    ax.set_ylabel('Score'); ax.set_title('Model Comparison: Clean vs Perturbed Test Sets'); ax.set_xticks(x); ax.set_xticklabels(metrics_labels); ax.legend(); ax.set_ylim(0, 1.0); ax.grid(True, axis='y', alpha=0.3)\n",
    "    plt.tight_layout(); plt.savefig(f\"{Config.OUTPUT_DIR}/metrics_comparison.png\", dpi=150); plt.show()\n",
    "    print(f\"\n",
    "Visualizations saved to {Config.OUTPUT_DIR}/\")\n",
    "else:\n",
    "    print(\"Synthetic augmentation disabled; skipping comparison visualizations.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 15: Sample Predictions Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# CELL 15: SAMPLE PREDICTIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Skipping prediction visualization because COCO-style annotations are not generated in this pipeline.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 16: Save Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# CELL 16: SAVE EXPERIMENT SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "summary = {\n",
    "    'config': {\n",
    "        'image_size': Config.IMG_SIZE,\n",
    "        'num_epochs': Config.NUM_EPOCHS,\n",
    "        'batch_size': Config.BATCH_SIZE,\n",
    "        'learning_rate': Config.LR,\n",
    "        'iou_threshold': Config.IOU_THRESHOLD,\n",
    "        'conf_threshold': Config.CONF_THRESHOLD,\n",
    "        'use_yolo_direct': Config.USE_YOLO_DIRECT,\n",
    "        'enable_synth_aug': Config.ENABLE_SYNTH_AUG\n",
    "    },\n",
    "    'model_A_baseline': {\n",
    "        'training_history': history_A,\n",
    "        'test_clean': metrics_A_clean,\n",
    "    }\n",
    "}\n",
    "\n",
    "if Config.ENABLE_SYNTH_AUG and model_B is not None:\n",
    "    summary['model_B_augmented'] = {\n",
    "        'training_history': history_B,\n",
    "        'best_f1': best_f1_B\n",
    "    }\n",
    "\n",
    "with open(f\"{Config.OUTPUT_DIR}/experiment_summary.json\", 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXPERIMENT COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\"\"\n",
    "Saved outputs:\n",
    "  - Checkpoints: {Config.CHECKPOINT_DIR}/\n",
    "    - model_A_baseline_best.pth\n",
    "  - Visualizations: {Config.OUTPUT_DIR}/\n",
    "    - dataset_loading_test.png\n",
    "  - Summary: {Config.OUTPUT_DIR}/experiment_summary.json\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "### Key Fixes in This Version:\n",
    "1. **Box Format**: Proper conversion from COCO [x,y,w,h] to Faster R-CNN [x1,y1,x2,y2]\n",
    "2. **Evaluation**: Greedy matching sorted by confidence, proper FP/FN counting\n",
    "3. **Class Filtering**: Only count predictions with label=1 (person)\n",
    "4. **Debug Info**: TP/FP/FN printed each epoch for verification\n",
    "\n",
    "### Why Recall=1 Was Happening:\n",
    "- The original code may have had box format mismatches\n",
    "- Or the GT boxes were being compared incorrectly\n",
    "- This version properly handles all conversions\n",
    "\n",
    "### Swapping to YOLOv8:\n",
    "```python\n",
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8n.pt')\n",
    "model.train(data='data.yaml', epochs=6, imgsz=512, batch=4)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
